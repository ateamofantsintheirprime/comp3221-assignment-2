
class Client:
    def __init__(self, port, client_id):
        self.client_id = client_id
        self.data_size = 0
        self.port = port
        self.active = False
        self.in_queue = False
        self.latest_model = None
        self.latest_round = -1
        self.train_MSE = -1
        self.test_MSE = -1


import sys, os, torch, sklearn, socket, time, pickle, io, binascii
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader

from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split

import os
import json
import copy
import random
import numpy as np


client_id = sys.argv[1]
client_port = int(sys.argv[2])
ADDRESS = '127.0.0.1'
SERVER_PORT = 6000
LOCAL_EPOCHS = 10
LEARNING_RATE = 0.0000001
INPUT_FEATURES = 8
opt_method = bool(sys.argv[3])
batch_size = 64 # ?
client_ports = {"client1": 6001, 
               "client2": 6002,
               "client3": 6003,
               "client4": 6004,
               "client5": 6005
}


# Define loss function

loss = nn.MSELoss(reduction='mean')

local_model = nn.Linear(INPUT_FEATURES, 1)


optimiser = torch.optim.SGD(local_model.parameters(), lr=LEARNING_RATE)

def model_to_bytes(model):
    buffer = io.BytesIO()
    torch.save(model.state_dict(), buffer)
    return buffer.getvalue()

def model_from_bytes(bytes):

    buffer = io.BytesIO(bytes)
    state_dict = torch.load(buffer)

    model = nn.Linear(state_dict['weight'].shape[1], state_dict['weight'].shape[0])
    model.load_state_dict(state_dict)
    return model

def update_model(model):
    # Copy new model data to local model
    for old, new in zip(local_model.parameters(), model.parameters()):
        old.data = new.data.clone()

def train(epochs):
    local_model.train()
    for epoch in range(1, epochs + 1):
        local_model.train()
        for batch_idx, (X, y) in enumerate(trainloader):
            optimiser.zero_grad()
            output = local_model(X).reshape(-1)
            loss_val = loss(output, y)
            loss_val.backward()
            optimiser.step()
    return loss_val.data
    

def test():
    local_model.eval()
    mse = 0
    for x, y in testloader:
        y_pred = local_model(x)
        y = y.unsqueeze(1)

        mse += loss(y_pred, y)
    return mse.tolist()

def send_model(model, round_number, test_MSE, train_MSE):
    
    model_bytes = model_to_bytes(model)
    
    client_message = pickle.dumps({"type": "model",
            "id" : client_id,
            "model" : model_bytes,
            "round" : round_number,
            "test_MSE": test_MSE,
            "train_MSE": train_MSE})

    send_socket.sendto(client_message, (ADDRESS,SERVER_PORT))
    
def get_data(client):
    train_MedInc = []
    train_HouseAge = []
    train_AveRooms = []
    train_AveBedrms = []
    train_Population = []
    train_AveOccup = []
    train_Latitude = []
    train_Longitude = []
    train_MedHouseVal = []

    test_MedInc = []
    test_HouseAge = []
    test_AveRooms = []
    test_AveBedrms = []
    test_Population = []
    test_AveOccup = []
    test_Latitude = []
    test_Longitude = []
    test_MedHouseVal = []

    filename = "FLData/calhousing_train_" + client + ".csv"
    with open(filename, "r") as file:
        #ignores the first line of names of dataset
        next(file)
        for line in file:
            split_data = line.split(",")
            train_MedInc.append(float(split_data[0]))
            train_HouseAge.append(float(split_data[1]))
            train_AveRooms.append(float(split_data[2]))
            train_AveBedrms.append(float(split_data[3]))
            train_Population.append(float(split_data[4]))
            train_AveOccup.append(float(split_data[5]))
            train_Latitude.append(float(split_data[6]))
            train_Longitude.append(float(split_data[7]))
            train_MedHouseVal.append(float(split_data[8]))

    filename = "FLData/calhousing_test_" + client + ".csv"
    with open(filename, "r") as file:
        #ignores the first line of names of dataset
        next(file)
        for line in file:
            split_data = line.split(",")
            test_MedInc.append(float(split_data[0]))
            test_HouseAge.append(float(split_data[1]))
            test_AveRooms.append(float(split_data[2]))
            test_AveBedrms.append(float(split_data[3]))
            test_Population.append(float(split_data[4]))
            test_AveOccup.append(float(split_data[5]))
            test_Latitude.append(float(split_data[6]))
            test_Longitude.append(float(split_data[7]))
            test_MedHouseVal.append(float(split_data[8]))

    x_train_np = np.column_stack((train_MedInc, train_HouseAge, train_AveRooms, train_AveBedrms, train_Population, train_AveOccup, train_Latitude, train_Longitude))
    x_test_np = np.column_stack((test_MedInc, test_HouseAge, test_AveRooms, test_AveBedrms, test_Population, test_AveOccup, test_Latitude, test_Longitude))
    
    x_train = torch.Tensor(x_train_np).view(-1,8).type(torch.float32)
    x_test = torch.Tensor(x_test_np).view(-1,8).type(torch.float32)
    
    y_train = torch.Tensor(train_MedHouseVal).type(torch.float32)
    y_test = torch.Tensor(test_MedHouseVal).type(torch.float32)

    return x_train, x_test, y_train, y_test, len(train_MedHouseVal), len(test_MedHouseVal)

client_port = client_ports.get(client_id)
train_X, test_X, train_Y, test_Y, train_samples, test_samples = get_data(client_id)

send_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
client_message = {"type": "handshake",
                "id" : client_id,
                "data_size" : train_samples}
message_bytes = pickle.dumps(client_message)

time.sleep(5)
send_socket.sendto(message_bytes, (ADDRESS,SERVER_PORT)) 
print(f"{client_id} sent handshake")
receive_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
receive_socket.bind((ADDRESS,client_port))

train_data = [(x, y) for x, y in zip(train_X, train_Y)]
test_data = [(x, y) for x, y in zip(test_X, test_Y)]

if not opt_method: # Set batch size to full training data size for regular GD
    batch_size = len(train_Y)

trainloader = DataLoader(train_data, batch_size=batch_size)
testloader = DataLoader(train_data, batch_size=len(test_Y))

round_number = 0
while True:
    # print("I am {}".format(client_id))
    message, server_address = receive_socket.recvfrom(2048)
    message = pickle.loads(message)
    if not message or message["type"] == "finish":
        break
    
    if message["type"] == "model":
        # print("Received new global model")
        model = model_from_bytes(message['model'])
        update_model(model)
        round_number = message["round"]
        train_MSE = train(LOCAL_EPOCHS)
        # print("Training MSE: {}".format(train_MSE))
        test_MSE = test()
        # print("Testing MSE: {}".format(test_MSE))
        log_input = "TestMSE: {}, TrainMSE: {}\n".format(test_MSE, train_MSE)
        file_name = "Logs/" + client_id + ".txt"
        with open(file_name, "a") as myfile:
            myfile.write(log_input)
        
        # print("Sending new local model")
        send_model(local_model, round_number, test_MSE, train_MSE)

        import sys, os, torch, socket, threading, copy, random, time, pickle, io, binascii
import torch.nn as nn 

import torch.nn.functional as F
import numpy as np
from torch.utils.data import DataLoader
from client import Client
import matplotlib
import matplotlib.pyplot as plt

from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split


COMMUNICATION_ROUNDS = 20
CLIENT_COUNT = 5 # dont change this
ADDRESS = '127.0.0.1'
INPUT_FEATURES = 8

port = int(sys.argv[1])
sub_client = int(sys.argv[2])
test_mse = []

clients = {
    'client1' : Client(6001, "client1"),
    'client2' : Client(6002, "client2"),
    'client3' : Client(6003,"client3"),
    'client4' : Client(6004,"client4"),
    'client5' : Client(6005,"client5")
}

def send_finish_message():
    sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    message = pickle.dumps({"type": "finish"})
    print("Sending finish message")
    for id in clients.keys():
        client = clients[id]
        sock.sendto(message, (ADDRESS,client.port))

def add_client(id, data_size):
    if clients[id] == True:
        raise Exception
    clients[id].active = True
    clients[id].in_queue = True
    clients[id].data_size = data_size
    print(f"Received handshake from {id}")

def receive_packet(socket):
    message, client_address = socket.recvfrom(4096)
    message = pickle.loads(message)
    if message["type"] == "handshake":
        add_client(message['id'], message['data_size'])
    if message["type"] == "model":
        add_model(message)

def listening_loop(socket):
    while True:
        receive_packet(socket)

def add_model(message):
    client_id = message['id']
    if client_id not in clients.keys():
        print(f"error, client {client_id} attempted to send a model before handshaking")
        return
    clients[client_id].latest_model = model_from_bytes(message['model'])
    
    clients[client_id].latest_round = message['round']
    clients[client_id].train_MSE = message['train_MSE']
    clients[client_id].test_MSE = message['test_MSE']

def wait_for_client_training(round_number):
    all_clients_completed = False
    while not all_clients_completed:
        all_clients_completed = True
        test = 0
        usable_clients = [c for c in clients.values() if c.active]
        for c in usable_clients:
            if c.latest_round != round_number:
                all_clients_completed = False
                time.sleep(1) # dont want to spam too hard
                break

def get_total_data_size() -> int:
    return sum([c.data_size for c in clients.values()])


def aggregate_models(global_model):
    # Zero out global model
    for param in global_model.parameters():
        param.data = torch.zeros_like(param.data)
    
    # Not all clients will be active
    usable_clients = [c for c in clients.values() if c.active]
    
    # Get selection of clients for aggregating based on subsampling specifications
    aggregate_clients = usable_clients
    if sub_client != 0:
        aggregate_clients = random.sample(usable_clients, sub_client)

    # Aggregate sampled client models into global model
    t_mse = 0
    for client in aggregate_clients:
        print("Getting local model from: ".format(client.client_id))
        t_mse += client.test_MSE / len(aggregate_clients)
        for server_param, user_param in zip(global_model.parameters(), client.latest_model.parameters()):
            sample_size_ratio = client.data_size / get_total_data_size()
            server_param.data = server_param.data + user_param.data.clone() * sample_size_ratio
    print("Broadcasting new global model")
    test_mse.append(t_mse)   

def model_to_bytes(model):
    buffer = io.BytesIO()
    torch.save(model.state_dict(), buffer)
    return buffer.getvalue()

def model_from_bytes(bytes):

    buffer = io.BytesIO(bytes)
    state_dict = torch.load(buffer)

    model = nn.Linear(state_dict['weight'].shape[1], state_dict['weight'].shape[0])
    model.load_state_dict(state_dict)
    return model

def distribute_global_model(model, round_number):
    sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    model_bytes = model_to_bytes(model)

    message = pickle.dumps({
        "type" : "model",
        "model" : model_bytes,
        "round" : round_number
    })
    for id in clients.keys():
        client = clients[id]
        if client.in_queue:
            client.in_queue = False
            client.active = True
        sock.sendto(message, (ADDRESS, client.port))

def get_num_active_clients(clients):
    active_clients = 0
    for c in clients.values():
        if c.active:
            active_clients += 1
    
    return active_clients

if port != 6000:
    print("Port Server Must be 6000")

print("starting up server")

s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
s.bind((ADDRESS, port))

#Waits until first connection is made and adds it to client list.

message, client_address = s.recvfrom(2048)
message = pickle.loads(message)
if message["type"] == "handshake":
    add_client(message['id'], message['data_size'])
else:
    raise Exception
#Once the first connection is made, the program waits 30 seconds before moving on.

listen_thread = threading.Thread(target=listening_loop, args=(s,))
listen_thread.daemon = True
listen_thread.start()

time.sleep(30) # wait 10 seconds for now
print("Starting Federated Learning Now")

global_model = nn.Linear(INPUT_FEATURES, 1)


for i in range(COMMUNICATION_ROUNDS):
    print("Global Iteration {}:".format(i))
    print("Total Number of clients: {}".format(get_num_active_clients(clients)))

    distribute_global_model(global_model, i)
    wait_for_client_training(i)
    aggregate_models(global_model)
    #print(f"ROUND: {i}, mse:", test_mse[-1])
#After T training rounds are completed, send finish messages to clients and close sockets
print(test_mse)
send_finish_message()
listen_thread.join(timeout=1)

# plt.figure(1,figsize=(5, 5))
# plt.plot(test_mse, label="FedAvg", linewidth  = 1)
# #plt.ylim([0.9,  0.99])
# plt.legend(loc='upper right', prop={'size': 12}, ncol=2)
# plt.ylabel('Testing MSE')
# plt.xlabel('Global rounds')
# plt.show()

clear;python3 COMP3221_FLServer.py 6000 0 & python3 COMP3221_FLClient.py client1 6001 0 &  python3 COMP3221_FLClient.py client2 6002 0 & python3 COMP3221_FLClient.py client3 6003 0 &  python3 COMP3221_FLClient.py client4 6004 0 & python3 COMP3221_FLClient.py client5 6005 0;
clear;python3 COMP3221_FLServer.py 6000 1 & python3 COMP3221_FLClient.py client1 6001 1 &  python3 COMP3221_FLClient.py client2 6002 1 & python3 COMP3221_FLClient.py client3 6003 1 &  python3 COMP3221_FLClient.py client4 6004 1 & python3 COMP3221_FLClient.py client5 6005 1;
clear;python3 COMP3221_FLServer.py 6000 2 & python3 COMP3221_FLClient.py client1 6001 1 &  python3 COMP3221_FLClient.py client2 6002 1 & python3 COMP3221_FLClient.py client3 6003 1 &  python3 COMP3221_FLClient.py client4 6004 1 & python3 COMP3221_FLClient.py client5 6005 1;
clear;python3 COMP3221_FLServer.py 6000 3 & python3 COMP3221_FLClient.py client1 6001 1 &  python3 COMP3221_FLClient.py client2 6002 1 & python3 COMP3221_FLClient.py client3 6003 1 &  python3 COMP3221_FLClient.py client4 6004 1 & python3 COMP3221_FLClient.py client5 6005 1;
clear;python3 COMP3221_FLServer.py 6000 4 & python3 COMP3221_FLClient.py client1 6001 1 &  python3 COMP3221_FLClient.py client2 6002 1 & python3 COMP3221_FLClient.py client3 6003 1 &  python3 COMP3221_FLClient.py client4 6004 1 & python3 COMP3221_FLClient.py client5 6005 1;
clear;python3 COMP3221_FLServer.py 6000 0 & python3 COMP3221_FLClient.py client1 6001 1 &  python3 COMP3221_FLClient.py client2 6002 1 & python3 COMP3221_FLClient.py client3 6003 1 &  python3 COMP3221_FLClient.py client4 6004 1 & python3 COMP3221_FLClient.py client5 6005 1;
